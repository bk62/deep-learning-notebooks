{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "collapsed_sections": [
        "15Dhpy7vcwPH"
      ],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyOfrEwuHvYLf5tTcUfWosET",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/bk62/deep-learning-notebooks/blob/main/generative_deep_learning/01_CNN_from_scratch.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        ">[-1. Dataset: Fashion MNIST](#updateTitle=true&folderId=1mwghr2cgAwLd91FL_Ep6CoG2qkkpYyUK&scrollTo=Kue5MyJJvn6o)\n",
        "\n",
        ">[Prelude: Image classification with MLP](#updateTitle=true&folderId=1mwghr2cgAwLd91FL_Ep6CoG2qkkpYyUK&scrollTo=QPcJWJ7ovZgU)\n",
        "\n",
        ">>[Model](#updateTitle=true&folderId=1mwghr2cgAwLd91FL_Ep6CoG2qkkpYyUK&scrollTo=QwAUO7ogdHzI)\n",
        "\n",
        ">>[Training](#updateTitle=true&folderId=1mwghr2cgAwLd91FL_Ep6CoG2qkkpYyUK&scrollTo=xxLzE6mpdJ50)\n",
        "\n",
        ">[CNN from scratch](#updateTitle=true&folderId=1mwghr2cgAwLd91FL_Ep6CoG2qkkpYyUK&scrollTo=kb8UhiA_BcGv)\n",
        "\n",
        ">>[Model](#updateTitle=true&folderId=1mwghr2cgAwLd91FL_Ep6CoG2qkkpYyUK&scrollTo=G9XX7NUkdMID)\n",
        "\n",
        ">>[Sanity check](#updateTitle=true&folderId=1mwghr2cgAwLd91FL_Ep6CoG2qkkpYyUK&scrollTo=uGGcVomedOEG)\n",
        "\n",
        ">>[Training](#updateTitle=true&folderId=1mwghr2cgAwLd91FL_Ep6CoG2qkkpYyUK&scrollTo=_BFzSjfEVE8j)\n",
        "\n",
        ">>[Final result](#updateTitle=true&folderId=1mwghr2cgAwLd91FL_Ep6CoG2qkkpYyUK&scrollTo=15Dhpy7vcwPH)\n",
        "\n"
      ],
      "metadata": {
        "colab_type": "toc",
        "id": "8cSmwJWWBsOZ"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "# -1. Dataset: Fashion MNIST"
      ],
      "metadata": {
        "id": "Kue5MyJJvn6o"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "from torch import nn\n",
        "from torch.utils.data import DataLoader\n",
        "from torchvision import datasets\n",
        "from torchvision.transforms import ToTensor\n",
        "\n",
        "%matplotlib inline\n",
        "from matplotlib import pyplot as plt"
      ],
      "metadata": {
        "id": "GBtJV1d_v8Hj"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Download training data from open datasets.\n",
        "training_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=True,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")\n",
        "\n",
        "# Download test data from open datasets.\n",
        "test_data = datasets.FashionMNIST(\n",
        "    root=\"data\",\n",
        "    train=False,\n",
        "    download=True,\n",
        "    transform=ToTensor(),\n",
        ")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xR3wdyO_vmTC",
        "outputId": "eded645d-dd30-4845-9d14-4d40ad5fd784"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-images-idx3-ubyte.gz to data/FashionMNIST/raw/train-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 26421880/26421880 [00:01<00:00, 18477531.45it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw/train-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 29515/29515 [00:00<00:00, 305910.35it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/train-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 4422102/4422102 [00:00<00:00, 5332748.36it/s]\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-images-idx3-ubyte.gz to data/FashionMNIST/raw\n",
            "\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz\n",
            "Downloading http://fashion-mnist.s3-website.eu-central-1.amazonaws.com/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "100%|██████████| 5148/5148 [00:00<00:00, 6513507.39it/s]"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Extracting data/FashionMNIST/raw/t10k-labels-idx1-ubyte.gz to data/FashionMNIST/raw\n",
            "\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "batch_size = 64\n",
        "\n",
        "# Create data loaders.\n",
        "train_dataloader = DataLoader(training_data, batch_size=batch_size)\n",
        "test_dataloader = DataLoader(test_data, batch_size=batch_size)\n",
        "\n",
        "for X, y in test_dataloader:\n",
        "    print(f\"Shape of X [N, C, H, W]: {X.shape}\")\n",
        "    print(f\"Shape of y: {y.shape} {y.dtype}\")\n",
        "    break"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6VloAU0zvxlA",
        "outputId": "33232b2f-5272-4273-80f0-692da2325fd9"
      },
      "execution_count": 3,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Shape of X [N, C, H, W]: torch.Size([64, 1, 28, 28])\n",
            "Shape of y: torch.Size([64]) torch.int64\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Get cpu, gpu or mps device for training.\n",
        "device = (\n",
        "    \"cuda\"\n",
        "    if torch.cuda.is_available()\n",
        "    else \"mps\"\n",
        "    if torch.backends.mps.is_available()\n",
        "    else \"cpu\"\n",
        ")\n",
        "print(f\"Using {device} device\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "c1w_EPStv3Sw",
        "outputId": "3abac2ff-eab1-4734-bb98-04239889b972"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Using cuda device\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 0. Prelude: Image classification with MLP"
      ],
      "metadata": {
        "id": "QPcJWJ7ovZgU"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "QwAUO7ogdHzI"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class MLP(nn.Module):\n",
        "  def __init__(self, n):\n",
        "    super().__init__()\n",
        "    self.flatten = nn.Flatten()\n",
        "    self.stack = nn.Sequential(\n",
        "        nn.Linear(n, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 512),\n",
        "        nn.ReLU(),\n",
        "        nn.Linear(512, 10),\n",
        "        nn.Softmax(1),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    x = self.flatten(x)\n",
        "    probs = self.stack(x)\n",
        "    return probs\n",
        "\n",
        "model = MLP(28*28).to(device)\n",
        "print(model)\n",
        "\n",
        "total_params = 0\n",
        "for name, params in model.named_parameters():\n",
        "  print(name, params.numel())\n",
        "  total_params += params.numel()\n",
        "print(f\"Total params: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QjyBKudiveuQ",
        "outputId": "6e387cd2-b64d-451b-b8ac-231581c2e63a"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MLP(\n",
            "  (flatten): Flatten(start_dim=1, end_dim=-1)\n",
            "  (stack): Sequential(\n",
            "    (0): Linear(in_features=784, out_features=512, bias=True)\n",
            "    (1): ReLU()\n",
            "    (2): Linear(in_features=512, out_features=512, bias=True)\n",
            "    (3): ReLU()\n",
            "    (4): Linear(in_features=512, out_features=10, bias=True)\n",
            "    (5): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "stack.0.weight 401408\n",
            "stack.0.bias 512\n",
            "stack.2.weight 262144\n",
            "stack.2.bias 512\n",
            "stack.4.weight 5120\n",
            "stack.4.bias 10\n",
            "Total params: 669706\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "xxLzE6mpdJ50"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "9hXufLIs4Dyp"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def train(dataloader, model, loss_fn, optimizer):\n",
        "    size = len(dataloader.dataset)\n",
        "    model.train()\n",
        "    for batch, (X, y) in enumerate(dataloader):\n",
        "        X, y = X.to(device), y.to(device)\n",
        "\n",
        "        # Compute prediction error\n",
        "        pred = model(X)\n",
        "        loss = loss_fn(pred, y)\n",
        "\n",
        "        # Backpropagation\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        optimizer.zero_grad()\n",
        "\n",
        "        if batch % 100 == 0:\n",
        "            loss, current = loss.item(), (batch + 1) * len(X)\n",
        "            print(f\"loss: {loss:>7f}  [{current:>5d}/{size:>5d}]\")\n",
        "\n",
        "\n",
        "def test(dataloader, model, loss_fn):\n",
        "    size = len(dataloader.dataset)\n",
        "    num_batches = len(dataloader)\n",
        "    model.eval()\n",
        "    test_loss, correct = 0, 0\n",
        "    with torch.no_grad():\n",
        "        for X, y in dataloader:\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            pred = model(X)\n",
        "            test_loss += loss_fn(pred, y).item()\n",
        "            correct += (pred.argmax(1) == y).type(torch.float).sum().item()\n",
        "    test_loss /= num_batches\n",
        "    correct /= size\n",
        "    print(f\"Test Error: \\n Accuracy: {(100*correct):>0.1f}%, Avg loss: {test_loss:>8f} \\n\")"
      ],
      "metadata": {
        "id": "DC8RtHxd6KHG"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss, opt)\n",
        "    test(test_dataloader, model, loss)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_4arB8Us6y9b",
        "outputId": "8468fc8c-fcbf-45dd-93e2-a6c07b3dc0de"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 2.303153  [   64/60000]\n",
            "loss: 1.767309  [ 6464/60000]\n",
            "loss: 1.636677  [12864/60000]\n",
            "loss: 1.702919  [19264/60000]\n",
            "loss: 1.725078  [25664/60000]\n",
            "loss: 1.678324  [32064/60000]\n",
            "loss: 1.632666  [38464/60000]\n",
            "loss: 1.650415  [44864/60000]\n",
            "loss: 1.698492  [51264/60000]\n",
            "loss: 1.658300  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.7%, Avg loss: 1.643641 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.612846  [   64/60000]\n",
            "loss: 1.615519  [ 6464/60000]\n",
            "loss: 1.597406  [12864/60000]\n",
            "loss: 1.678277  [19264/60000]\n",
            "loss: 1.662121  [25664/60000]\n",
            "loss: 1.647781  [32064/60000]\n",
            "loss: 1.592896  [38464/60000]\n",
            "loss: 1.605031  [44864/60000]\n",
            "loss: 1.628901  [51264/60000]\n",
            "loss: 1.656769  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.7%, Avg loss: 1.644313 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.615448  [   64/60000]\n",
            "loss: 1.582928  [ 6464/60000]\n",
            "loss: 1.585325  [12864/60000]\n",
            "loss: 1.645452  [19264/60000]\n",
            "loss: 1.651247  [25664/60000]\n",
            "loss: 1.634772  [32064/60000]\n",
            "loss: 1.600036  [38464/60000]\n",
            "loss: 1.671901  [44864/60000]\n",
            "loss: 1.670008  [51264/60000]\n",
            "loss: 1.637831  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.5%, Avg loss: 1.644551 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.607527  [   64/60000]\n",
            "loss: 1.611731  [ 6464/60000]\n",
            "loss: 1.586711  [12864/60000]\n",
            "loss: 1.666098  [19264/60000]\n",
            "loss: 1.664463  [25664/60000]\n",
            "loss: 1.644666  [32064/60000]\n",
            "loss: 1.598904  [38464/60000]\n",
            "loss: 1.624648  [44864/60000]\n",
            "loss: 1.642517  [51264/60000]\n",
            "loss: 1.621502  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 79.7%, Avg loss: 1.663186 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.580433  [   64/60000]\n",
            "loss: 1.630634  [ 6464/60000]\n",
            "loss: 1.605672  [12864/60000]\n",
            "loss: 1.682909  [19264/60000]\n",
            "loss: 1.660785  [25664/60000]\n",
            "loss: 1.599373  [32064/60000]\n",
            "loss: 1.647424  [38464/60000]\n",
            "loss: 1.646401  [44864/60000]\n",
            "loss: 1.648649  [51264/60000]\n",
            "loss: 1.663093  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 81.9%, Avg loss: 1.641174 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.628098  [   64/60000]\n",
            "loss: 1.602619  [ 6464/60000]\n",
            "loss: 1.540864  [12864/60000]\n",
            "loss: 1.645406  [19264/60000]\n",
            "loss: 1.663211  [25664/60000]\n",
            "loss: 1.618882  [32064/60000]\n",
            "loss: 1.584464  [38464/60000]\n",
            "loss: 1.620810  [44864/60000]\n",
            "loss: 1.651626  [51264/60000]\n",
            "loss: 1.632694  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 82.5%, Avg loss: 1.635040 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.600846  [   64/60000]\n",
            "loss: 1.605932  [ 6464/60000]\n",
            "loss: 1.599272  [12864/60000]\n",
            "loss: 1.655480  [19264/60000]\n",
            "loss: 1.612049  [25664/60000]\n",
            "loss: 1.638454  [32064/60000]\n",
            "loss: 1.558763  [38464/60000]\n",
            "loss: 1.629462  [44864/60000]\n",
            "loss: 1.621681  [51264/60000]\n",
            "loss: 1.579182  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.6%, Avg loss: 1.615129 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.551450  [   64/60000]\n",
            "loss: 1.605215  [ 6464/60000]\n",
            "loss: 1.552122  [12864/60000]\n",
            "loss: 1.644052  [19264/60000]\n",
            "loss: 1.679368  [25664/60000]\n",
            "loss: 1.611576  [32064/60000]\n",
            "loss: 1.573041  [38464/60000]\n",
            "loss: 1.648637  [44864/60000]\n",
            "loss: 1.644093  [51264/60000]\n",
            "loss: 1.613939  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 83.7%, Avg loss: 1.623933 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.554927  [   64/60000]\n",
            "loss: 1.602942  [ 6464/60000]\n",
            "loss: 1.554901  [12864/60000]\n",
            "loss: 1.646181  [19264/60000]\n",
            "loss: 1.642173  [25664/60000]\n",
            "loss: 1.601727  [32064/60000]\n",
            "loss: 1.584257  [38464/60000]\n",
            "loss: 1.634386  [44864/60000]\n",
            "loss: 1.649033  [51264/60000]\n",
            "loss: 1.617436  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.8%, Avg loss: 1.612563 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.549615  [   64/60000]\n",
            "loss: 1.633019  [ 6464/60000]\n",
            "loss: 1.570159  [12864/60000]\n",
            "loss: 1.608854  [19264/60000]\n",
            "loss: 1.619048  [25664/60000]\n",
            "loss: 1.600266  [32064/60000]\n",
            "loss: 1.589825  [38464/60000]\n",
            "loss: 1.633674  [44864/60000]\n",
            "loss: 1.607384  [51264/60000]\n",
            "loss: 1.652983  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 84.9%, Avg loss: 1.611381 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final result\n",
        "Test set:\n",
        "\n",
        "Accuracy\n",
        "84.9%\n",
        "\n",
        "Loss\n",
        "1.611381"
      ],
      "metadata": {
        "id": "2grpM7YudW6L"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "x, y = test_data[0][0], test_data[0][1]\n",
        "with torch.no_grad():\n",
        "    x = x.to(device)\n",
        "    pred = model(x)\n",
        "    predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "    print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TErlgSnY7aCT",
        "outputId": "0a5be8dc-391a-4d37-9ef8-294daf6bff75"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Ankle boot\", Actual: \"Ankle boot\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "# 1. CNN from scratch"
      ],
      "metadata": {
        "id": "kb8UhiA_BcGv"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Model"
      ],
      "metadata": {
        "id": "G9XX7NUkdMID"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class SimpleCNN(nn.Module):\n",
        "  def __init__(self, n):\n",
        "    super().__init__()\n",
        "    self.stack = nn.Sequential(\n",
        "        # Conv 1\n",
        "        nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.LeakyReLU(),\n",
        "\n",
        "        # Conv 2\n",
        "        nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2),\n",
        "        nn.BatchNorm2d(32),\n",
        "        nn.LeakyReLU(),\n",
        "\n",
        "        # Conv 3\n",
        "        nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(),\n",
        "\n",
        "        # Conv 4\n",
        "        nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2),\n",
        "        nn.BatchNorm2d(64),\n",
        "        nn.LeakyReLU(),\n",
        "\n",
        "        nn.Flatten(),\n",
        "        nn.Linear(1024, 128),\n",
        "        nn.BatchNorm1d(num_features=128),\n",
        "        nn.LeakyReLU(),\n",
        "\n",
        "        # Dropout\n",
        "        nn.Dropout(0.5),\n",
        "\n",
        "        nn.Linear(128, 10),\n",
        "        nn.Softmax(dim=1),\n",
        "    )\n",
        "\n",
        "  def forward(self, x):\n",
        "    probs = self.stack(x)\n",
        "    return probs\n",
        "\n",
        "model = SimpleCNN(28).to(device)\n",
        "print(model)\n",
        "\n",
        "total_params = 0\n",
        "for name, params in model.named_parameters():\n",
        "  print(name, params.numel())\n",
        "  total_params += params.numel()\n",
        "print(f\"Total params: {total_params}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "xCQN1ZkJ7qO3",
        "outputId": "63674ce4-065b-4ca1-9a18-aeea2fb6706c"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "SimpleCNN(\n",
            "  (stack): Sequential(\n",
            "    (0): Conv2d(1, 32, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (1): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (2): LeakyReLU(negative_slope=0.01)\n",
            "    (3): Conv2d(32, 32, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (4): BatchNorm2d(32, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (5): LeakyReLU(negative_slope=0.01)\n",
            "    (6): Conv2d(32, 64, kernel_size=(3, 3), stride=(1, 1))\n",
            "    (7): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (8): LeakyReLU(negative_slope=0.01)\n",
            "    (9): Conv2d(64, 64, kernel_size=(3, 3), stride=(2, 2))\n",
            "    (10): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (11): LeakyReLU(negative_slope=0.01)\n",
            "    (12): Flatten(start_dim=1, end_dim=-1)\n",
            "    (13): Linear(in_features=1024, out_features=128, bias=True)\n",
            "    (14): BatchNorm1d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
            "    (15): LeakyReLU(negative_slope=0.01)\n",
            "    (16): Dropout(p=0.5, inplace=False)\n",
            "    (17): Linear(in_features=128, out_features=10, bias=True)\n",
            "    (18): Softmax(dim=1)\n",
            "  )\n",
            ")\n",
            "stack.0.weight 288\n",
            "stack.0.bias 32\n",
            "stack.1.weight 32\n",
            "stack.1.bias 32\n",
            "stack.3.weight 9216\n",
            "stack.3.bias 32\n",
            "stack.4.weight 32\n",
            "stack.4.bias 32\n",
            "stack.6.weight 18432\n",
            "stack.6.bias 64\n",
            "stack.7.weight 64\n",
            "stack.7.bias 64\n",
            "stack.9.weight 36864\n",
            "stack.9.bias 64\n",
            "stack.10.weight 64\n",
            "stack.10.bias 64\n",
            "stack.13.weight 131072\n",
            "stack.13.bias 128\n",
            "stack.14.weight 128\n",
            "stack.14.bias 128\n",
            "stack.17.weight 1280\n",
            "stack.17.bias 10\n",
            "Total params: 198122\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Sanity check"
      ],
      "metadata": {
        "id": "uGGcVomedOEG"
      }
    },
    {
      "cell_type": "markdown",
      "source": [
        "Checking that the sizes match our expectations:"
      ],
      "metadata": {
        "id": "CqUed_Z6O2YQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c1 = nn.Conv2d(in_channels=1, out_channels=32, kernel_size=3, stride=1)\n",
        "x = X[0]\n",
        "y1 = c1(x)\n",
        "x.shape, y1.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YTyrzwSdEprZ",
        "outputId": "58392c99-d8ec-4ad8-f257-7db2cd9db918"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 28, 28]), torch.Size([32, 26, 26]))"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "x11 = X[0:1]\n",
        "print(x11.shape)\n",
        "y11 = c1(x11)\n",
        "print(y11.shape)\n",
        "bn = nn.BatchNorm2d(num_features=32)\n",
        "y11bn = bn(y11)\n",
        "y11.shape, y11bn.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QYpKqofuTVt-",
        "outputId": "c66dc4f5-909a-4d90-dcd7-58946c4846ef"
      },
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "torch.Size([1, 1, 28, 28])\n",
            "torch.Size([1, 32, 26, 26])\n"
          ]
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([1, 32, 26, 26]), torch.Size([1, 32, 26, 26]))"
            ]
          },
          "metadata": {},
          "execution_count": 12
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "First Conv:\n",
        "\n",
        "In: 28 * 28 image with 1 channel\n",
        "\n",
        "Out: 26 * 26 with 32 channels"
      ],
      "metadata": {
        "id": "gDZ9reIYO9c0"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c2 = nn.Conv2d(in_channels=32, out_channels=32, kernel_size=3, stride=2)\n",
        "y2 = c2(y1)\n",
        "y1.shape, y2.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "frjPd0mFFMlw",
        "outputId": "565541ef-c799-4b3b-c6d9-f1c98bd88b9f"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 26, 26]), torch.Size([32, 12, 12]))"
            ]
          },
          "metadata": {},
          "execution_count": 13
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Second Conv:\n",
        "\n",
        "In: 26 * 26 image with 32 channels\n",
        "\n",
        "Out: 12 * 12 with 32 channels"
      ],
      "metadata": {
        "id": "gLtv4TxUPeb7"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c3 = nn.Conv2d(in_channels=32, out_channels=64, kernel_size=3, stride=1)\n",
        "y3 = c3(y2)\n",
        "y2.shape, y3.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NKebnIVIFRBj",
        "outputId": "a3c66a86-2373-4787-9637-b7f9c45b73bb"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([32, 12, 12]), torch.Size([64, 10, 10]))"
            ]
          },
          "metadata": {},
          "execution_count": 14
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Third Conv:\n",
        "\n",
        "In: 12 * 12 image with 32 channels\n",
        "\n",
        "Out: 10 * 10 with 64 channels"
      ],
      "metadata": {
        "id": "ioGycIJkP_QD"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "c4 = nn.Conv2d(in_channels=64, out_channels=64, kernel_size=3, stride=2)\n",
        "y4 = c4(y3)\n",
        "y3.shape, y4.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "U3j-KlpGGAVi",
        "outputId": "d3f3df75-4a7b-4b92-9f7b-6fec8f95cbd7"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([64, 10, 10]), torch.Size([64, 4, 4]))"
            ]
          },
          "metadata": {},
          "execution_count": 15
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Fourth (and final) Conv:\n",
        "\n",
        "In: 10 * 10 image with 64 channels\n",
        "\n",
        "Out: 4 * 4 with 64 channels\n",
        "\n",
        "Therefore, after all 4 convolutions, the input shape is\n",
        "`[64, 4, 4]` with\n",
        "$$\\textrm{num elements} =\n",
        "64 \\cdot 4 \\cdot 4 = 1024 $$"
      ],
      "metadata": {
        "id": "nkXa1epyQcAO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "x = X[0:2].to(device)\n",
        "y = model(x)\n",
        "x.shape, y.shape, y.sum(1)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "JznTKn8aRPRR",
        "outputId": "163880ec-2a0b-4164-919c-4dfc93336a4a"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(torch.Size([2, 1, 28, 28]),\n",
              " torch.Size([2, 10]),\n",
              " tensor([1., 1.], device='cuda:0', grad_fn=<SumBackward1>))"
            ]
          },
          "metadata": {},
          "execution_count": 20
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Training"
      ],
      "metadata": {
        "id": "_BFzSjfEVE8j"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "loss = nn.CrossEntropyLoss()\n",
        "opt = torch.optim.Adam(model.parameters(), lr=1e-3)"
      ],
      "metadata": {
        "id": "lYtRuet-V2R4"
      },
      "execution_count": 21,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 10\n",
        "for t in range(epochs):\n",
        "    print(f\"Epoch {t+1}\\n-------------------------------\")\n",
        "    train(train_dataloader, model, loss, opt)\n",
        "    test(test_dataloader, model, loss)\n",
        "print(\"Done!\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "zN9Fdo17Uf4O",
        "outputId": "554281b1-98f7-492d-9a58-30577262dc03"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 1\n",
            "-------------------------------\n",
            "loss: 1.561404  [   64/60000]\n",
            "loss: 1.588964  [ 6464/60000]\n",
            "loss: 1.524415  [12864/60000]\n",
            "loss: 1.606976  [19264/60000]\n",
            "loss: 1.573387  [25664/60000]\n",
            "loss: 1.613041  [32064/60000]\n",
            "loss: 1.576545  [38464/60000]\n",
            "loss: 1.606741  [44864/60000]\n",
            "loss: 1.576480  [51264/60000]\n",
            "loss: 1.545722  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 87.7%, Avg loss: 1.583819 \n",
            "\n",
            "Epoch 2\n",
            "-------------------------------\n",
            "loss: 1.607596  [   64/60000]\n",
            "loss: 1.579967  [ 6464/60000]\n",
            "loss: 1.517097  [12864/60000]\n",
            "loss: 1.574990  [19264/60000]\n",
            "loss: 1.576660  [25664/60000]\n",
            "loss: 1.629848  [32064/60000]\n",
            "loss: 1.592491  [38464/60000]\n",
            "loss: 1.590710  [44864/60000]\n",
            "loss: 1.549518  [51264/60000]\n",
            "loss: 1.561827  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.0%, Avg loss: 1.572419 \n",
            "\n",
            "Epoch 3\n",
            "-------------------------------\n",
            "loss: 1.543245  [   64/60000]\n",
            "loss: 1.600298  [ 6464/60000]\n",
            "loss: 1.519070  [12864/60000]\n",
            "loss: 1.599556  [19264/60000]\n",
            "loss: 1.551137  [25664/60000]\n",
            "loss: 1.594736  [32064/60000]\n",
            "loss: 1.535786  [38464/60000]\n",
            "loss: 1.578194  [44864/60000]\n",
            "loss: 1.528043  [51264/60000]\n",
            "loss: 1.594186  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 88.6%, Avg loss: 1.575083 \n",
            "\n",
            "Epoch 4\n",
            "-------------------------------\n",
            "loss: 1.574190  [   64/60000]\n",
            "loss: 1.574087  [ 6464/60000]\n",
            "loss: 1.495484  [12864/60000]\n",
            "loss: 1.544708  [19264/60000]\n",
            "loss: 1.568019  [25664/60000]\n",
            "loss: 1.584344  [32064/60000]\n",
            "loss: 1.555061  [38464/60000]\n",
            "loss: 1.573412  [44864/60000]\n",
            "loss: 1.534995  [51264/60000]\n",
            "loss: 1.588815  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.7%, Avg loss: 1.563744 \n",
            "\n",
            "Epoch 5\n",
            "-------------------------------\n",
            "loss: 1.543995  [   64/60000]\n",
            "loss: 1.563893  [ 6464/60000]\n",
            "loss: 1.505564  [12864/60000]\n",
            "loss: 1.575114  [19264/60000]\n",
            "loss: 1.550794  [25664/60000]\n",
            "loss: 1.584250  [32064/60000]\n",
            "loss: 1.564557  [38464/60000]\n",
            "loss: 1.535883  [44864/60000]\n",
            "loss: 1.521242  [51264/60000]\n",
            "loss: 1.541538  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 89.3%, Avg loss: 1.567043 \n",
            "\n",
            "Epoch 6\n",
            "-------------------------------\n",
            "loss: 1.528810  [   64/60000]\n",
            "loss: 1.557532  [ 6464/60000]\n",
            "loss: 1.511094  [12864/60000]\n",
            "loss: 1.565977  [19264/60000]\n",
            "loss: 1.531421  [25664/60000]\n",
            "loss: 1.581767  [32064/60000]\n",
            "loss: 1.533914  [38464/60000]\n",
            "loss: 1.557216  [44864/60000]\n",
            "loss: 1.531755  [51264/60000]\n",
            "loss: 1.540692  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.1%, Avg loss: 1.559853 \n",
            "\n",
            "Epoch 7\n",
            "-------------------------------\n",
            "loss: 1.552135  [   64/60000]\n",
            "loss: 1.554618  [ 6464/60000]\n",
            "loss: 1.495766  [12864/60000]\n",
            "loss: 1.554763  [19264/60000]\n",
            "loss: 1.540690  [25664/60000]\n",
            "loss: 1.559874  [32064/60000]\n",
            "loss: 1.529188  [38464/60000]\n",
            "loss: 1.543249  [44864/60000]\n",
            "loss: 1.520737  [51264/60000]\n",
            "loss: 1.558122  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.1%, Avg loss: 1.559469 \n",
            "\n",
            "Epoch 8\n",
            "-------------------------------\n",
            "loss: 1.530761  [   64/60000]\n",
            "loss: 1.568758  [ 6464/60000]\n",
            "loss: 1.479200  [12864/60000]\n",
            "loss: 1.557485  [19264/60000]\n",
            "loss: 1.559336  [25664/60000]\n",
            "loss: 1.578602  [32064/60000]\n",
            "loss: 1.522403  [38464/60000]\n",
            "loss: 1.543613  [44864/60000]\n",
            "loss: 1.539030  [51264/60000]\n",
            "loss: 1.525529  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.6%, Avg loss: 1.554952 \n",
            "\n",
            "Epoch 9\n",
            "-------------------------------\n",
            "loss: 1.527196  [   64/60000]\n",
            "loss: 1.530205  [ 6464/60000]\n",
            "loss: 1.500066  [12864/60000]\n",
            "loss: 1.571180  [19264/60000]\n",
            "loss: 1.511405  [25664/60000]\n",
            "loss: 1.556939  [32064/60000]\n",
            "loss: 1.526779  [38464/60000]\n",
            "loss: 1.527488  [44864/60000]\n",
            "loss: 1.524501  [51264/60000]\n",
            "loss: 1.542260  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.6%, Avg loss: 1.554081 \n",
            "\n",
            "Epoch 10\n",
            "-------------------------------\n",
            "loss: 1.552060  [   64/60000]\n",
            "loss: 1.589190  [ 6464/60000]\n",
            "loss: 1.487282  [12864/60000]\n",
            "loss: 1.518564  [19264/60000]\n",
            "loss: 1.517999  [25664/60000]\n",
            "loss: 1.542170  [32064/60000]\n",
            "loss: 1.535555  [38464/60000]\n",
            "loss: 1.537737  [44864/60000]\n",
            "loss: 1.530246  [51264/60000]\n",
            "loss: 1.510236  [57664/60000]\n",
            "Test Error: \n",
            " Accuracy: 90.5%, Avg loss: 1.556153 \n",
            "\n",
            "Done!\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "## Final result\n",
        "Test set:\n",
        "\n",
        "Accuracy\n",
        "90.5%\n",
        "\n",
        "Loss\n",
        "1.556153"
      ],
      "metadata": {
        "id": "15Dhpy7vcwPH"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "classes = [\n",
        "    \"T-shirt/top\",\n",
        "    \"Trouser\",\n",
        "    \"Pullover\",\n",
        "    \"Dress\",\n",
        "    \"Coat\",\n",
        "    \"Sandal\",\n",
        "    \"Shirt\",\n",
        "    \"Sneaker\",\n",
        "    \"Bag\",\n",
        "    \"Ankle boot\",\n",
        "]\n",
        "\n",
        "model.eval()\n",
        "for ix in range(1, 10):\n",
        "  x, y = test_data[ix][0], test_data[ix][1]\n",
        "  with torch.no_grad():\n",
        "      x = x.to(device)\n",
        "      pred = model(x.view(1, 1, 28, 28)) # batch size 1\n",
        "      predicted, actual = classes[pred[0].argmax(0)], classes[y]\n",
        "      print(f'Predicted: \"{predicted}\", Actual: \"{actual}\"')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Qyy-_soTU3cD",
        "outputId": "fa989da8-aaf5-43d5-9540-07f24ebf2a13"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Predicted: \"Pullover\", Actual: \"Pullover\"\n",
            "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
            "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
            "Predicted: \"Shirt\", Actual: \"Shirt\"\n",
            "Predicted: \"Trouser\", Actual: \"Trouser\"\n",
            "Predicted: \"Coat\", Actual: \"Coat\"\n",
            "Predicted: \"Shirt\", Actual: \"Shirt\"\n",
            "Predicted: \"Sandal\", Actual: \"Sandal\"\n",
            "Predicted: \"Sneaker\", Actual: \"Sneaker\"\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "ZO2YFknWao-C"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}